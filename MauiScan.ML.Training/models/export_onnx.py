"""
å¯¼å‡º PyTorch æ¨¡å‹åˆ° ONNX æ ¼å¼
"""

import torch
import onnx
from pathlib import Path
from corner_detector import PPTCornerDetector


def export_to_onnx(
    model_path: str,
    output_path: str,
    input_size: tuple[int, int] = (512, 512),
    opset_version: int = 14
):
    """
    å°† PyTorch æ¨¡å‹å¯¼å‡ºä¸º ONNX

    Args:
        model_path: PyTorch æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ (.pth)
        output_path: è¾“å‡º ONNX æ–‡ä»¶è·¯å¾„
        input_size: è¾“å…¥å›¾ç‰‡å°ºå¯¸ (H, W)
        opset_version: ONNX opset ç‰ˆæœ¬
    """
    print(f"ğŸ“¦ å¼€å§‹å¯¼å‡º ONNX æ¨¡å‹...")
    print(f"  - PyTorch æ¨¡å‹: {model_path}")
    print(f"  - è¾“å‡ºè·¯å¾„: {output_path}")
    print(f"  - è¾“å…¥å°ºå¯¸: {input_size}")

    # 1. åŠ è½½ PyTorch æ¨¡å‹
    model = PPTCornerDetector(pretrained=False)
    checkpoint = torch.load(model_path, map_location='cpu')

    # å…¼å®¹ä¸åŒçš„ checkpoint æ ¼å¼
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)

    model.eval()

    # 2. åˆ›å»ºè™šæ‹Ÿè¾“å…¥
    dummy_input = torch.randn(1, 3, input_size[0], input_size[1])

    # 3. å¯¼å‡º ONNX
    torch.onnx.export(
        model,
        dummy_input,
        output_path,
        export_params=True,
        opset_version=opset_version,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['coordinates', 'confidence'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'coordinates': {0: 'batch_size'},
            'confidence': {0: 'batch_size'}
        }
    )

    print(f"âœ… ONNX æ¨¡å‹å¯¼å‡ºæˆåŠŸ!")

    # 4. éªŒè¯ ONNX æ¨¡å‹
    print(f"\nğŸ” éªŒè¯ ONNX æ¨¡å‹...")
    onnx_model = onnx.load(output_path)
    onnx.checker.check_model(onnx_model)
    print(f"âœ… ONNX æ¨¡å‹éªŒè¯é€šè¿‡!")

    # 5. æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    import os
    file_size_mb = os.path.getsize(output_path) / (1024 * 1024)
    print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"  - æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
    print(f"  - Opset ç‰ˆæœ¬: {opset_version}")
    print(f"  - è¾“å…¥: input [1, 3, {input_size[0]}, {input_size[1]}]")
    print(f"  - è¾“å‡º 1: coordinates [1, 8]")
    print(f"  - è¾“å‡º 2: confidence [1, 1]")

    # 6. æµ‹è¯• ONNX Runtime æ¨ç†
    print(f"\nğŸ§ª æµ‹è¯• ONNX Runtime æ¨ç†...")
    import onnxruntime as ort
    import numpy as np

    session = ort.InferenceSession(output_path)
    test_input = np.random.randn(1, 3, input_size[0], input_size[1]).astype(np.float32)

    outputs = session.run(None, {'input': test_input})
    coords, conf = outputs

    print(f"âœ… ONNX Runtime æ¨ç†æˆåŠŸ!")
    print(f"  - åæ ‡è¾“å‡º: {coords.shape}, èŒƒå›´ [{coords.min():.3f}, {coords.max():.3f}]")
    print(f"  - ç½®ä¿¡åº¦è¾“å‡º: {conf.shape}, å€¼ {conf[0, 0]:.3f}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='å¯¼å‡º ONNX æ¨¡å‹')
    parser.add_argument('model_path', type=str, help='PyTorch æ¨¡å‹è·¯å¾„ (.pth)')
    parser.add_argument('--output', type=str, default='ppt_corner_detector.onnx',
                        help='è¾“å‡º ONNX æ–‡ä»¶å')
    parser.add_argument('--input-size', type=int, default=512, help='è¾“å…¥å›¾ç‰‡å°ºå¯¸')
    parser.add_argument('--opset', type=int, default=14, help='ONNX opset ç‰ˆæœ¬')

    args = parser.parse_args()

    export_to_onnx(
        model_path=args.model_path,
        output_path=args.output,
        input_size=(args.input_size, args.input_size),
        opset_version=args.opset
    )

    print(f"\nğŸ‰ å®Œæˆ! ONNX æ¨¡å‹å·²ä¿å­˜åˆ°: {args.output}")
    print(f"\nğŸ“Œ ä¸‹ä¸€æ­¥:")
    print(f"  1. å°† {args.output} å¤åˆ¶åˆ° C# é¡¹ç›®:")
    print(f"     MauiScan/MauiScan/Resources/Raw/{args.output}")
    print(f"  2. åœ¨ C# ä¸­ä½¿ç”¨ OnnxInferenceService åŠ è½½æ¨¡å‹")


if __name__ == '__main__':
    main()
